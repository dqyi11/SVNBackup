% THIS FILE IS USED TO STORE GLOBAL VARIABLES.

%% GLOBAL VARIABLES WE NEED INITIALLY
global DATA; 	% FOR ALL DATA IN MAT FILE
global TRAIN; 	% 400*6205 DOCUMENTS * WORDS IN VOCABULARY
global VOCAB; 	% 6205*1 VOCABULARY
global LABEL;	% 1*400 LABELS FOR DOCUMENTS FOR VERIFICATION

TRAIN=DATA.classic400;
VOCAB=DATA.classicwordlist;
LABEL=DATA.truelabels;


%% VARIABLES FOR ALGORITHM SIMPLIFICATION
global cTOPIC	% # OF TOPICS WE ASSUMED
cTOPIC=3;

global cWORDS 	% # OF WORDS 6205
cWORDS=size(VOCAB,1);

global cDOCU	% # OF DOCUMENTS 400
cDOCU=size(TRAIN,1);

global qWORD;	% # WORDS BELONG TO TOPIC (TOPIC*WORDS)
qWORD=zeros(cTOPIC,cWORDS);

global nDOCU;	% # WORDS BELONG TO TOPIC IN DOCUMENT (TOPIC*DOCUMENTS)
nDOCU=zeros(cTOPIC,cDOCU);

global zDOCU;	% ON THE BASE OF DOCUMENTS (# DOCU * (WORD,TOPIC) * # CURRENT DOCU LENGTH)
zDOCU=cell(cDOCU,2);	% DIMENSION 2 IS FLEXIBLE LENGTH, DECIDED WHEN INITIALED.

% NOTE: WE DONT NEED TO STORE PROB DISTRIBUTION FOR EACH WORD OCCURENCE
% IT CHANGES ALL THE TIME


%% PARAMETERS FOR GIBBS SAMPLING
global ALPHA;	% INTUT: PSEDO WORDS FOR EACH TOPIC. (TOPIC*1)
global BETA;	% INTUT: OCCURRENCE PROBABILITY FOR EACH WORD ON DOCUMENT LEVEL (WORD*1)

intCount=20/cTOPIC;
ALPHA=ones(cTOPIC,1)*intCount;

intPROB=0.1;
BETA=ones(cWORDS,1)*intPROB;

global EPOCH;	% # EPOCH WE NEED
EPOCH=200;

global THETA;	% TOPIC PROBABILITY FOR EACH DOCUMENT (TOPIC*DOCUMENT)
THETA=zeros(cTOPIC,cDOCU);

global PHI;		% WORD PROBABILITY FOR EACH TOPIC (TOPIC*WORD)
PHI=zeros(cTOPIC,cWORDS);

global dTOPIC;	% # TOPIC ON WHOLE DATABASE (TOPIC*1)
dTOPIC=zeros(cTOPIC,1);