\section{Swarm analysis}
\label{sec:swarm}

%\subsection{Consensus of a swarm}

%\begin{itemize}
%\item Combinations of ISS parts are ISS
%\item Swarm as such a combination
%\item Conditions where update is ISS
%\item trivially at stagnation. But also when on a single hill
%\end{itemize}

%\begin{itemize}
%\item Bound on swarm for the single hill case (perhaps as function of the width of the hill?
%Or width of the hill as a percentage of the feasible region?)
%\item test on 2-d case to show that the bound can prevent a particle from reaching another hill.
%This is one form of the swarm failing to converge the global optimal.
%\item Can we look at parameters for the whole swarm?
%\end{itemize}

In section \ref{sec:particle}, we can see the pros and cons of the search capacity of a particle.
The particle is in a randomized walk in an attractive potential field defined by the global best and the personal best.
There exist a lot of factors that prevents the particle reaching the optimal.
The swarm initializes the particles randomly in the search space and has the particles searching the optimal simultaneously, which forms a beam-search style.
The import of interaction topology enhances the search capability, which makes it more than a beam-search style optimization method.
In this section, we analyze the star topology of global best update.
In this topology, the global best update imports the competition among the particles.
The particle finds a new global best becomes the leader of the swarm.

%unimodal
%\begin{itemize}
%\item bound -> convergence
%\item swarm converges more quickly
%\end{itemize}
%multimodal
%\begin{itemize}
%\item bounded converge to bound
%\item explore better
%\end{itemize}

As we can see in Figure \ref{fig:pso_sys_flow}, the global best update provides a global best $ x^{G} $ and feedbacks into each particle.
The update rule of the global best update is the same with that of the personal best update.
Several of the properties of the personal best update can be derived here.
We have Lemma \ref{lem:unimodal:swarm:gb_up_iss}.

\begin{mylem}
\label{lem:unimodal:swarm:gb_up_iss}
If $ f(x^{*}) - \alpha_{2} ( |x| ) \leq  f(x) \leq f(x^{*}) - \alpha_{1} ( |x| ) $, when $ x^{G} = x^{*} $, the global best update component is input-to-state stable.
$ \alpha_{1} () $ and $ \alpha_{2} () $ are $ K_{\infty} $-function.
\begin{proof}
Same as that in the proof of Lemma \ref{lem:unimodal:particle:input_iss}.
\end{proof}
\end{mylem}

We can naturally derive Theorem \ref{thm:unimodal:swarm:garuantee_converge}.

\begin{mythm}
\label{thm:unimodal:swarm:garuantee_converge}
When $ x^{G} = x^{*} $,  if $ f(x^{*}) - \alpha_{2} ( |x| ) \leq  f(x) \leq f(x^{*}) - \alpha_{1} ( |x| ) $ and $ \gamma_{s} \circ \gamma_{p} (s)  < s $, the particles in the swarm will converge to $ x^{*} $ if the position-update component of the particle is input-to-state stable.
$ \gamma_{s} () $ is the gain of the global best update component and $ \gamma_{p} () $ is the gain of the particle component.
\begin{proof}
When both the particles and the global best update are input-to-state stable, we can have the particles all gradually converge to $ x^{*} $, by Corollary 4.2 in \cite{Jiang2001857}.
\end{proof}
\end{mythm}

As we know, when $ x^{G}(k) = x^{*} $, the swarm becomes only a set of particles without interactions.
Thus, we are here interested with how the global best $ x^{G} $ can converge to $ x^{*} $.

\subsection{Unimodal fitness distribution}

Due to the potential competition in the swarm, if there is always a particle finds a better solution till the optimal is reached, the swarm can always find the optimal in the unimodal case.
We have Theorem \ref{thm:unimodal:swarm:converge}.

\begin{mythm}
\label{thm:unimodal:swarm:converge}
In the unimodal case, when there are more than two particles, $ x^{G} $ converges to $ x^{*} $ if all the particles has input-to-state stable position update component.
\begin{proof}
There are two cases, $ x^{G} = x^{*} $ and $ x^{G} \not = x^{*} $
If the global best is $ x^{*} $, the particles will gradually converge to $ x^{*} $ by Lemma \ref{lem:unimodal:particle:nonstop}.
If the global best is not $ x^{*} $, $ x^{G} $ converges to $ x^{*} $.
This can be proved using contradiction.
Assume that $ x^{G} $ will not converge to $ x^{*} $.
It means that at least more than one particle stop finding better solution.
This contradicts with Theorem \ref{thm:unimodal:particle:better}.
\end{proof}
\end{mythm}

%[TODO:] More particles --> convergence rate
%This is hard. Because convergence rate is not a constant.

%\subsubsection{Simulation}

\begin{mylem}
The probability that a swarm finds a better solution is higher than that of any particle.
The bigger number of the particles is, the higher probability that a swarm finds a better solution is.
\begin{proof}
Let $ P_{s} $ be the probability that a swarm of size $ N $ finds a better solution.
Let $ P_{i}, i \in [1, N] $ be the probability that particle $ i $ finds a better solution.
We can have  $ P_{s} = 1 - \prod_{i=1}^{N} ( 1 - P_{i} ) $.
By writing it as $ P = 1 - ( 1 - P_{i} ) \prod_{j=1, j \not = i}^{N}  ( 1 - P_{j} ) $ and $ \prod_{j=1, j \not = i}^{N}  ( 1 - P_{j} ) \leq 1 $, we know $ \forall i \in [1, N], P > P_{i} $.
If we add a new particle to the swarm, we have
$ P_{s'}  = 1 - (1- P_{s}) *(1-P_{i+1}) $. 
Similarly, $ P_{s'} \geq P_{s} $.
Thus we can say that the increase of the particle number will not decrease the probability that the swarm finds a better solution.
\end{proof}
\end{mylem}

\begin{mythm}
The make of a swarm brings higher convergence rate.
\begin{proof}
Define the convergence rate as $ $.
Because the probability that a swarm finds a better solution is higher than the probability that any particle finds a better solution.
We know that the swarm has a higher convergence rate.
\end{proof}
\end{mythm}


\subsection{Multi-modal fitness distribution}

When the fitness distribution is not unimodal, there exists more varieties in the movement patterns of the particles.
The probability that a particle find a new global best depends on the position, the personal best and the fitness distribution near around.

The increase of the number of the particles raise the probability that the swarm can find a new global best.
We have Theorem \ref{thm:multimodal:swarm:prob}.

As we know that the movement of a particle is bounded, because of the import of the stochastic terms, we can view the exploration as sequentially sampling on the solution space.
There are two factors that determine the capability of the exploration.
\begin{itemize}
\item how the samples are distributed;
\item how is the boundary of the samples.
\end{itemize}

\begin{myprop}
\label{prop:swarm:more_samplings}
Running a particle ( with same initial position, global best and personal best ) at different time generates different samplings.
\end{myprop}
Naturally, more particles form the parallel sampling, which generate more diverse samplings in one iteration.

It is not surprising that a swarm brings a bigger exploration range.
Because the exploration range of a swarm is the join of the exploration ranges of all the particles.
However, the explore range of each single particle might be changed as well, due to the change of the global best.
We have Theorem \ref{thm:swarm:expand_range}.

\begin{mythm}
\label{thm:swarm:expand_range}
When a particle is not in the modal that has the optimal solution, joining into a swarm increases the probability that the particle moves into a better region.
\begin{proof}
Because we have that the movement boundary of a particle depends on the difference between the personal best and the global best.
When a particle is not in the modal that has the optimal solution, the global best is more likely to deviate from the personal best.
This gives a bigger movement bound to the particle, which makes a higher probability that the particle can move into a better region.
\end{proof}
\end{mythm}

%\begin{mythm}
%\label{thm:multimodal:swarm:prob}
%The probability that the swarm finds a better global best depends on the probabilities that the particles find better global best, which is
%\begin{equation}
%\label{eq:prob_sum}
%P = 1 - \prod_{i=1}^{N} ( 1 - P_{i} ),
%\end{equation}
%$ P_{i} $ is the probability of particle $ i $ finds a new global best
%and $ P $ is the probability that the swarm finds a new global best.
%\begin{equation}
%\label{eq:prob_less}
%\forall i \in [1, N], P > P_{i}.
%\end{equation}
%\begin{proof}
%The search process is a competition among the particles in the swarm.
%If the swarm does not find a better global best, it means that none of the particle finds a better global best.
%For particle $ i $, the probability that a new global best cannot be found is $ 1 - P_{i} $.
%Because the global best is constant, the movements of the particles are independent in the search process.
%Thus, the probability that no particle finds a new global best becomes
%$ \prod_{i=1}^{N} ( 1 - P_{i} ) $.
%Then we can know that the probability that a new global best can be found by the swarm.
%By writing \eqref{eq:prob_sum} as $ P = 1 - ( 1 - P_{i} ) \prod_{j=1, j \not = i}^{N}  ( 1 - P_{j} ) $ and $ \prod_{j=1, j \not = i}^{N}  ( 1 - P_{j} ) \leq 1 $,
%we have \eqref{eq:prob_less}.
%\end{proof}
%\end{mythm}

%\begin{figure}
%\centering
%includegraphics[width=0.7\linewidth]{./fig/probRise}
%\caption{The probability increases with the particle number.}
%\label{fig:probRise}
%\end{figure}

%Figure \ref{fig:probRise} illustrates how the probability of the swarm increases with the number of the particles, assuming that the probabilities of all the particles are the same.
%The uniformly random initialization enables the diversity of the probabilities of the particles, which should increase the probability of the swarm as well.

%\subsubsection{Simulation}

\subsection{Value of a swarm}

%Being on one hill is the unlikely case bound in the multi hill case.
%Might not seem useful but is the essence of what makes a swarm a swarm.
%Bounds the swarm to a region around p-bests where g-best has been unable to pull other particles to its hill.
%For a function with narrow hills, g-bests on a narrow hills is less likely to capture another particle, thus the swarm searches more, for functions with broad hills, p-gest are more likely to be pulled to g-bests hill and search there.
%Thus swarm diversity is the mechanism that allows the swarm to not converge when searching is likely needed but focus and converge when the fitness landscape appear to favor exploitation.
%This does not happen at stagnation and does not happen without multiple members. <need to say this in a more mathematical way>>

%example ?? function for exploration case
%example sphere function for the exploitation case
%try to use bound as a function of hill width metric

%Rastrigin as a counter example? Does it get stuck or just sample for ever? It certainly runs longer.


\subsubsection{Competition}

The competition is imported when there is a swarm.
The competition prevents the global best stuck in a position, especially a local optimal.
As a result, the probability that the global optimal can be found would be increased.

\subsubsection{Diversity}

Swarm also brings the diversity.
Because the particles are randomly initialized.
As the particles are initialized at different positions, the diversity of the probabilities of finding a better solution $ P_{i} $ is increased.
By Theorem \ref{thm:unimodal:swarm:prob}, we know that the probability of the swarm that finds a better solution is also increased.

At the same time, there also exists diversity of the personal best.
This also enlarges the inconsistencies between the personal best and the global best.
By Lemma \ref{lem:particle:bound_mov}, we know that the explore range of each particle can be increased.
As a result, the swarm could explore a larger region.


\subsection{Diversity injection}

%Work with the Rastrigin function has lead others to experiment with diversity injection to prevent pre-mature convergence (or prevent convergence at all)
%I am not sure, do we want it to converge? ever?
%On what basis would I propose a new algorithm?
%Show that it would converge based on ISS?