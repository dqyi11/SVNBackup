\section{Approximate Anytime Solution}
\label{sec:submod_orienteer}

In this section, we use backtracking to estimate the maximum total reward and use this estimate as our search heuristic.
We then use an expanding tree to create an anytime algorithm approximate solution to the submodular orienteering problem on the multi-partite graph.

\subsection{Using the Search Heuristic from Backtracking}
\label{sec:backtrack}

In a graph search process, if a sub-path  $ \{ v_{1} , \cdots , v_{t'} \} $ has been visited, we can use the following property to approximate the maximum future reward. 
\begin{propty}
\label{prop:h2p}
\begin{equation}
\nonumber
\label{eq:h2p}
h( x_{1}, \cdots x_{t'} ) = \max_{x_{t'+1} \in V(t'+1) \land (v_{t'}, x_{t'+1}) \in E} u(x_{t'+1} \mid x_{1}, \cdots x_{t'} ).
\end{equation}
\end{propty}
Property \ref{prop:h2p} implies that the maximum future reward at partition $ V(t) $ can be estimated from the maximum total reward at partition $ V(t+1) $.
This means that the maximum total rewards could be estimated by using a backtracking process.
We propose a backtracking process in Algorithm \ref{alg:Backtrack}.

\begin{algorithm}
\caption{ $ \mathbf{BT}( \{ v_{1} , \cdots , v_{t'} \}, G ) $ - Backtracking }
\label{alg:Backtrack}
\begin{algorithmic}[1]
\REQUIRE
a sub-path $ \{ v_{1} , \cdots , v_{t'} \} $, and multi-partite graph $ G = ( V, E, T ) $
\ENSURE $ \hat{u}( v_{1} , \cdots , v_{t'} , v_{t'+1} ), \forall v_{t'+1} \in V(t'+1) $ \\
\FOR{ $ t=T:-1:t'+1 $ }
\FOR{ $ v_{t} \in V(t) $}
\IF {$ t == T $}
\STATE $ \hat{u}(v_{T} \mid v_{1} , \cdots , v_{t'} ) = f(v_{T} \mid v_{1} , \cdots , v_{t'} ) $
\ELSE
\STATE $ \hat{h}( v_{1} , \cdots , v_{t'},  v_{t} ) = \max_{ { x_{t+1} \in V(t+1) } \land { (v_{t}, x_{t+1}) \in E } } \hat{u}(x_{t+1} \mid v_{1} , \cdots , v_{t'} ) $
\STATE $ \hat{u}(v_{t} \mid v_{1} , \cdots , v_{t'} ) = f(v_{t} \mid v_{1} , \cdots , v_{t'} ) + \hat{h}( v_{1} , \cdots , v_{t'} , v_{t}) $
\ENDIF
\ENDFOR
\ENDFOR
\RETURN $ \hat{u}( v_{1} , \cdots , v_{t'}, v_{t'+1} ), \forall v_{t'+1} \in V(t'+1)  $
\end{algorithmic}
\end{algorithm}

Algorithm \ref{alg:Backtrack} estimates the maximum total rewards of the vertices in $ V(t'+1) $.
The backtracking starts at partition $ V(T) $ and goes back to $ V(t'+1) $ in order to propagate the estimated maximum future rewards.
For a vertex $ v(t) $, the maximum future reward is estimated based on the estimated maximum total rewards of all the connected vertices in partition $ V(t+1) $.
The estimated total reward is then obtained by adding the estimated instant reward of $ v(t) $ with the estimated maximum future reward of $ v(t) $. 
The backtracking process in Algorithm \ref{alg:Backtrack} satisfies Lemma \ref{lem:underestimate}.

\begin{lem}
\label{lem:underestimate}
``Backtracking" in Algorithm \ref{alg:Backtrack} never underestimates the maximum total reward, which means 
\begin{equation}
\label{eq:underestimate}
\forall t \geq t',
\hat{u}( x_{t} \mid v_{1} , \cdots , v_{t'} ) \geq u( x_{t} \mid v_{1} , \cdots , v_{t'} ).
\end{equation}
\begin{proof}
The proof is given in Appendix \ref{app:lemma_under}.
\end{proof}
\end{lem}
Note that Lemma \ref{lem:underestimate} holds even when there are multiple vertices in a multi-partite graph generated from same cell.
This is because the submodularity of $ f() $ is preserved and the proof depends primarily on submodularity.
However, multiple vertices generated from same cell in a path increase the degree to which the reward is overestimated.

\subsection{Expanding Tree Search}
\label{sec:expanding_tree}

Since the heuristic is not guaranteed to produce an optimal solution, we create an anytime algorithm that allows us to continue the search process until a time limit is exceeded or the search is completed exhaustively.
In order to track the anytime search process, the algorithm uses an expanding tree. The expanding tree is the tree produced by repeated depth-first traversals of the multi-partite graph~\cite{rosen2011discrete}.

\begin{mydef}[\textbf{Expanding Tree}]
\label{def:expanding_tree}
An expanding tree $ G_{T} = (N, L, T) $ obtained from a multi-partite graph $ G = (V, E, T) $ is the tree produced by a depth first traversal of $ G $.
$ T $ is the depth of the tree, which is determined by the number of partitions in a multi-partite graph $ G $.
$ N $ is the node set. Each $ n_{t}^{i(j)} \in N $ indicates the relevant vertex in the multi-partite graph $ G $, in which $ t $ shows the index of the time partition, $ i $ shows the index of the corresponding vertex from within that partition and $ (j) $ shows the index of a vertex in $ V(t-1) $ that has an out edge to vertex $ i $.
$ L $ is the directed link set. $ (n^{i(k)}_{t}, n^{j(i)}_{t+1})  \in L $ is determined by $ (v^{i}_{t}, v^{j}_{t+1} ) \in E $.
\end{mydef}
We assign the {\em type} to each node, which are \emph{New} (a node has been created but not expanded), 
\emph{Expanded} (a node that has all child nodes created) and 
\emph{Frozen} (a node that has been created but will not be expanded).
Each path in an expanding tree is derived from a unique depth-first traversal of the corresponding mutli-partite graph.
We use $ v(n^{j(i)}_{t+1}) $ to denote a vertex mapped from a node.
For a node $ n_{t}^{i(j)} $, we use $ path(n_{t}^{i(j)}) $ to denote the implicit path from the start position to the corresponding vertex of the multi-partite graph, the cardinality of which is $ t $.

We can now present Algorithm \ref{alg:RecursiveBacktrack} for a single search iteration.
It is used as one run in the anytime framework.

\begin{algorithm}
\caption{ $ \mathbf{NERB}( n_{t'}, G, G_{T} ) $ - Node Expanding with Recursive Backtracking }
\label{alg:RecursiveBacktrack}
\begin{algorithmic}[1]
\REQUIRE 
Expanding Node $ n_{t'} $, Multi-partite graph $ G = (V, E, T) $, Expanding tree $ G_{T} = (N, L, T) $
\ENSURE $ solution $ of a complete path
\STATE $ solution = path(n_{t'}) $ 
\FOR{ $ t=t':1:T-1 $ }
\STATE  Create all $ child(n_{t'}) = \{ n_{t'+1} \mid v(n_{t'+1}) \in V(t'+1) \land (v(n_{t'}), v(n_{t'+1})) \in E  \} $
\STATE  Add $ child(n_{t'}) $ as the child nodes of $ n_{t'} $
\STATE  $ n_{t'}.state = \mbox{\emph{Expanded}} $
\STATE  $ \hat{u}( v_{t'+1} \mid path(n_{t'}) ) = \mathbf{BT}( path(n_{t'}) , G ) $
\STATE  $ \hat{n}_{t'+1} = \arg \max_{n_{t'+1} \in child(n_{t'})} \hat{u}( n_{t'+1} \mid path(n_{t'}) ) $
\STATE  $ solution = solution \bigcup \{ \hat{n}_{t'+1} \} $
\ENDFOR 
\RETURN $ solution $
\end{algorithmic}
\end{algorithm}

\subsection{Adding node freeze to the expanding tree}
\label{sec:node_freeze}

Because Lemma \ref{lem:underestimate} tells us that the backtracking process never underestimates the maximum total reward of a node, we can use the estimated maximum total reward of a node to evaluate whether the node might lead to a path that returns a bigger reward than the current best one.
A node is not in a path that has bigger reward if its estimated value is smaller than the current best solution.
We can freeze this node, which means that we are not going to expand any of its descendant nodes.
At each iteration we find a new solution, we can call a node freeze process to update the states of the nodes in the expanding tree.
This process is given in Algorithm~\ref{alg:FreezeNode}.

\begin{algorithm}
\caption{ $ \mathbf{NF}( G_{T}, \theta^{*} ) $ - Node Freeze}
\label{alg:FreezeNode}
\begin{algorithmic}[1]
\REQUIRE 
an expanding tree $ G_{T} = (N, L, T) $, the reward of found maximum reward path $ \theta^{*} $
\FOR{$ n_{t} \in N $ \AND $ n_{t}.state == \mbox{\emph{New}} $}
\IF{ $  f(path(n_{t})) + \hat{h}(path(n_{t})) \leq \theta^{*} $ }
\STATE $ n_{t}.state = \mbox{\emph{Frozen}} $
\ENDIF
\ENDFOR
\end{algorithmic}
\end{algorithm}

Algorithm \ref{alg:Anytime} combines Algorithm \ref{alg:Backtrack}, Algorithm \ref{alg:RecursiveBacktrack}, and Algorithm \ref{alg:FreezeNode} to yield the anytime algorithm.
The expanding tree starts with just a root node, which is the start vertex.
When a node is created, the state of the node is \emph{New}.
Expanding a node in Algorithm \ref{alg:Anytime} means creating all of its children nodes and changing the state of this node to \emph{Expanded}.
When a child node is created, the estimated maximum total reward is calculated using Algorithm \ref{alg:Backtrack} and stored.
Each run of Algorithm \ref{alg:RecursiveBacktrack} returns a complete path as a solution.
When a new complete path has been returned, the freeze process defined in Algorithm \ref{alg:FreezeNode} is executed by checking estimated maximum total rewards stored in each nodes in the state of \emph{New}.
The next run of the search starts from the {\emph New} node  $ n_{t} $ that has the largest estimated reward $  f(path(n_{t})) + \hat{h}(path(n_{t})) $.
Starting from this node, the next call to Algorithm \ref{alg:RecursiveBacktrack} generates another complete path.
This anytime algorithm stops at a pre-specified number of iterations or when there is no {\em New} node remaining. 

\begin{algorithm}
\caption{Anytime Algorithm Framework}
\label{alg:Anytime}
\begin{algorithmic}[1]
\REQUIRE 
Expanding Tree $ G_{T} = (N, L, T) $, and multi-partite graph $ G = (V, E, T) $;
\STATE Initial expanding tree $ G_{t}(N, L, T) $ with $ v_{1} $ as root node
\STATE $ maxPath = NULL $, $ newPath = NULL $
\STATE $ n' = G_{T}.root $
\WHILE { $ n' != NULL $ }
\STATE $ newPath = \mathbf{NERB}( n', G, G_{T} ) $
\IF {$ (f(newPath) > f(maxPath))  $}
\STATE $ maxPath = newPath $
\STATE post $ maxPath $
\ENDIF
\STATE $ \mathbf{NF}( G_{T}, f(maxPath) ) $
\STATE $ n' = \arg \max_{ \{n \mid n \in N \land n.state == \mbox{\emph{New}} \} } ( f(path(n)) + \hat{h}(path(n)) ) $
\ENDWHILE 
\end{algorithmic}
\end{algorithm}

Algorithm \ref{alg:Anytime} is optimal as shown in Theorem \ref{thm:optimal} given here.

\begin{thm} 
\label{thm:optimal}
The anytime algorithm framework in Algorithm \ref{alg:Anytime} can always find an optimal solution given enough time.
\end{thm}
\begin{proof}
The proof is by contradiction and is similar in spirit to the proof of optimality for the well-known A* algorithm.
Since Algorithm \ref{alg:Anytime} keeps expanding until no \emph{New} nodes remain, as long as any node in the optimal path will never be frozen, the search will reach the optimal terminal node.

Assume that one of the nodes $ n^{*}_{t} $ in the optimal path can be frozen.
This means that 
$ f(path(n^{*}_{t}) +  \hat{h}(path(n^{*}_{t})) ) \leq f(path(n'_{T})) $,
in which $ n'_{T} $ is another terminal node but not the terminal node for the optimal path.
As a result, when $ n'_{T} $ has been reached, it will freeze node $ n^{*}_{t} $. 

However, since node $ n^{*}_{t} $ is in a path to an optimal terminal node, $ f(path(n^{*}_{t})) + h(path(n^{*}_{t})) > f(path(n'_{T})) $.
Also we have $ f(path(n^{*}_{t})) + \hat{h}(path(n^{*}_{t})) \geq f(path(n^{*}_{t})) + h(path(n^{*}_{t})) $ by Lemma \ref{lem:underestimate}.
Thus we have $ f(path(n^{*}_{t})) + \hat{h}(path(n^{*}_{t}) > f(path(n'_{T})) $, which is a contradiction.

Therefore, a node in a path to an optimal terminal node will never be frozen by any non-optimal terminal node.
\end{proof}