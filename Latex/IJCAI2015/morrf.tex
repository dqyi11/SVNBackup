\documentclass{article}

\usepackage{ijcai15}

\usepackage{times}
\usepackage{comment}

\usepackage[pdftex]{graphicx}
\usepackage{comment}

\usepackage{algorithm}
\usepackage[noend]{algpseudocode}

\usepackage{amsfonts}
\usepackage{amsmath}

\usepackage{amsthm}
\newtheorem{thm}{Theorem}
\newtheorem{lem}{Lemma}
\newtheorem{asmp}{Assumption}
\newtheorem{defn}{Definition}

\usepackage{caption}
\usepackage{subcaption}

\title{ MORRF$^{*}$ : Sampling-Based Multi-Objective Motion Planning }

\author{Author Names Omitted for Anonymous Review. Paper-ID [add your ID here]}

\begin{document}

\maketitle

\begin{abstract}
Many robotic tasks require a robot to satisfy multiple performance objectives.  
For example, in path-planning, these objectives often include finding short paths that avoid risk and maximize the information obtained by the robot.  
Although there exist many algorithms for performing multi-objective optimization, few of these algorithms apply directly to robotic path-planning and fewer still are capable of finding the set of Pareto optimal solutions.  
We present the MORRF$^{*}$ (Multi-Objective Rapidly exploring Random Forest$^{*}$) algorithm, which is blends concepts from two different types of algorithms from the literature: RRT$^{*}$ for efficient path finding~\cite{Karaman.Frazzoli:RSS10} and a decomposition-based approach to multi-objective optimization~\cite{4358754}.  
The random forest uses two types of tree structures: a set of {\em reference trees} and a set of {\em subproblem trees}.  
Each reference tree explores a single objective, and the estimates from the set of reference trees are used to estimate what is called the {\em Utopia reference vector} required by the adapted multi-objective optimization algorithm.  
Each subproblem tree explores the space, seeking to find an optimal solution to the subproblem created by blending different objectives.  
We present a theoretical analysis that demonstrates that the algorithm asymptotically produces the set of Pareto optimal solutions, and use simulations to demonstrate the effectiveness and efficiency of MORFF* in approximating the Pareto set.
\end{abstract}

\begin{comment}
[Brief abstract submission] - February 8, 2015 (11:59 UTC-12)
[Final paper submission] - February 12, 2015 (11:59 UTC- 12)

Submitted technical papers must be no longer than seven pages in total: 
six pages for the main text of the paper (including all figures but excluding references), 
and one additional page for references. 
Note that the references page should only include references. 
\end{comment}

\section{Introduction}
\label{sec:intro}

\begin{comment}
(1) Why the multi-objective path planning is needed 
(2) Why the multi-objective path planning is hard (compare with a common multi-objective optimization problem)
\end{comment}

Many tasks assigned to robots are complex, can be performed in several different ways, and must satisfy several different performance objectives.  
For example, a robot in a search task may be expected to maximize the area that covers while minimizing energy consumption and avoiding risk (see, for example~\cite{yi2014supporting,mei2005deployment}). 
As another example, a robot manipulator may need to satisfy performance criteria  related to movement, joint velocities, joint accelerations, etc.~\cite{Pires2004}.

%In many real applications of the robots, the complexity of tasks inherently implies more than single objective to be reached.
%A robot in a search task is usually expected to maximize the search coverage with a consideration of the energy efficiency so that the execution time could also be expanded~\cite{yi2014supporting}. 
%If there exists risk in the working environment, the robot should also try to avoid dangerous regions.
%In robot arm manipulation planning, there usually exist several criteria to be considered as well~\cite{Pires2004}, for example, movement, joint velocities, joint accelerations and etc. 

The most commonly applied method for finding a solution to a multi-objective optimization problem is to optimize a single objective created by a weighted summation of the multiple objectives.  
Naturally, in path-planning the properties of the path produced by this optimization depends strongly on how different objectives are weighted, and this means that either the programmer, designer, or a human teammate must decide how to assign the weights so that the qualitative behavior matches what is intended.  
In addition to the burden this places on the human operator, optimizing a weighted sum does not work when the multiple objectives are very difficult to compare or are expressed in incommensurate units.

In response to these challenges, it is useful of find {\em the set of payoff dominant solutions} to the multi-objective path-planning problem, meaning the set of solutions for which there is no other solution that produces better payoffs for every objective.   
This paper uses the economics term {\em Pareto optimal} to denote a payoff dominant solution.  Although not demonstrated in this paper, we propose that if an algorithm could produce the set of Pareto optimal solutions then a human could interactively explore this set to find one or more solutions that matches his or her expectations. 
The objective of this paper is to create an algorithm that efficiently finds the Pareto set in a multi-objective path-planning problem.

Most popular methods in multi-objective optimization don't naturally apply to path-planning problems~\cite{4358754,6600851}.
%{\sc Give a reference to a good review or a reference to a handful of representative multi-objective methods}
The main reason for this is that path-planning often represents the problem to be solved as a semi-structured tree with an exponential number of possible trajectories through the tree, and the number of evaluations of the objective function required by existing algorithms doesn't scale well when there are an exponential number of solutions. 
One approach to addressing this is to change the representation for a path by, for example, coding a path as a sequence of fixed-length line segments represented by direction~\cite{Ahmed2013,howlett2006learning} or waypoints~\cite{5160222,Pires2004}.  
This produces an encoding that can be ``fed into" an appropriate evolutionary algorithm to search for the Pareto set. 
Unfortunately, these approaches don't scale well for large problems because the number of segments required to represent the paths grows too quickly, and estimating the required number of segments {\em a priori} is very challenging.  
Another approach to solving the multi-objective path-planning problem is to represent the path as a point in a very high-dimensional vector space, each path corresponding to a different point in a potentially different dimensional space, and then use standard approaches to explore these spaces. 
Indeed, we will use this as to guide our solution, but the algorithm we present works when the obstacles in the path-planning space introduce discontinuities in these high-dimensional spaces, which limits the applicability of heuristic-based search approaches~\cite{5160222,4358754}.

The RRT (Rapidly exploring Random Tree) algorithm is popular for finding feasible solutions from a start position to a goal position in continuous or very large search spaces; it also works well when environments have complex obstacles. 
The reason that RRT is popular is that the tree structure tends to be find solutions very efficiently.
The RRT$^{*}$ algorithm was a recently introduced modification to RRT that is guaranteed to find an optimal path given enough sampling time~\cite{Karaman:2011:SAO:2000201.2000209,Karaman.Frazzoli:RSS10}.

The remainder of the paper presents the MORRF$^{*}$ (Multi-Objective Rapidly exploring Random Forest*) algorithm, which we used to find a set of Pareto optimal paths from a start position to a goal position.  
MORRF$^{*}$ blends concepts from RRT$^{*}$ a decomposition-based approach to multi-objective optimization~\cite{4358754}.  
The random forest uses two types of tree structures: a set of {\em reference trees} and a set of {\em subproblem trees}.  
Each reference tree explores a single objective, and the estimates from the set of reference trees are used to estimate what is called the {\em Utopia reference vector} required by the adapted multi-objective optimization algorithm.  
Each subproblem tree explores the space, seeking to find an optimal solution to the subproblem created by blending different objectives. 

The paper is structured as follows.  
Section~\ref{sec:related_works} reviews relevant work in multi-objective optimization and RRT-like path-planning. 
Section~\ref{sec:morrt} presents the MORRF$^{*}$ algorithm,  
Section~\ref{sec:theoretic_analysis} proves that the algorithm produces the Pareto frontier given enough sampling time, 
and Section~\ref{sec:simulation} uses simulations to illustrate the algorithm's performance.

\section{Related Work}
\label{sec:related_works}

An algorithm that discovers the set of Pareto optimal solutions must discover those solutions for which no other solution is better with respect to every objective.  A naive algorithm would do this by comparing every solution to every other solution, which works fine for problems with a small, discrete set of solutions, but does not work for continuous spaces or problems with exponential numbers of potential solutions.  
Consider Marler's and Arora's observation that ``no single approach is superior [for all problems].  
Rather, the selection of a specific method depends on the type of information given in the problem"~\cite{marler2004survey}.  
We note that (single objective) path-planning in a continuous state space is often efficiently performed using RRT* or other discretization-based approaches, and this suggests that we use a discretization-based approach, ruling out, for example, variational approaches to solving the problem.    

Given the restriction to approaches that use discretization-based approaches, prior work has modeled the space as a graph and applied a multi-objective A* search to find the solution~\cite{Mandow:2005:NAM:1642293.1642328}. 
The limitation of this approach is that it requires an {\em a priori} discretization rather than a discretization that is guided by the objectives as is done in RRT*; a coarse discretization throws away potentially valuable information and a fine discretization increases complexity and adds redundancy in the resulting graph structures.
Obstacles can cause problems for determining which cells in the discretized space are connected to which others, not so much in 2-D for a single robot but more so for planning the trajectory for a robotic manipulator.
Another approach that users an {\em a priori} discretization (and suffers from these limitations) is to encode a path as a sequence of directions from one cell to next cell and then using what the authors call the NSGA-II algorithm to find a set of Pareto optimal solutions in \cite{Ahmed2013}.  
Constrained splines have been introduced to interpolate a sequence of way points into a trajectory that avoids obstacles~\cite{6181426}, but the effect of the interpolation on the quality of the solution has not been evaluated.

% Evolutionary algorithms can be used to fine the Pareto set, but these approaches tend to be inefficient when applied to spaces with high dimensions~\cite{marler2004survey}.  For such spaces, small deviations in possible solutions may need to be considered in order to find an optimal solution, but this means exploring many possible solutions for problems with non-linearities or multiple local maxima.   A path in a fixed-length search tree of depth $d$ can be considered as a point in $\Re^d$, so tree-based approaches followed by an evolutionary "fine-tuning" stage risk running into the problems just listed with evolutionary approaches. 

In contrast to searching through and comparing solutions in order to find the Pareto optimal set, decomposition-based methods provide an attractive alternative.  
Indeed, the approach in this paper uses a decomposition-based method.  
MOEA-D is an algorithm that decomposes a multi-objective optimization problem into a class of subproblems~\cite{4358754}.  
Each subproblem uses a weighed blend of the various objectives to find specific points in the Pareto set or to guide the search for such points.  
Because we  will use this subproblem idea in our algorithm, it is useful to introduce some important notation.
Let $ \vec{\lambda} = [ \lambda_{1} , \cdots , \lambda_{K}  ]^{T} $ be a weighting vector such that $ \sum_{k=1}^{K} \lambda_{k} = 1 $.  Let $\{f_1(\cdot), f_2(\cdot), ... f_{K}(\cdot)\}$ denote the K-element set of objective functions, and let $x$ denote a potential solution.  Finally, let $ \vec{z}^{*} = [z^{*}_{1}, \cdots , z^{*}_{K}]^{T} $ denote the so-called ``Utopia" reference vector, described in more detail in the next section. 
Three types of decomposition methods are introduced in~\cite{4358754}.
\begin{itemize}
\item \emph{Weighted sum approach} \\
Maximize $ g^{ws} (x \mid \vec{\lambda}) = \sum_{k=1}^{K} \lambda_{k} f_{k} (x) $;
\item \emph{Tchebycheff approach} \\
Minimize $ g^{te} (x \mid \lambda , \vec{z}^{*}) = \max_{1 \leq k \leq K}  \{ \lambda_{k} | f_{k}(x) - z^{*}_{k}  | \} $;
\item \emph{Boundary intersection approach} \\
Minimize $ g^{bi} (x \mid \lambda , \vec{z}^{*} ) = d $, subject to $ \vec{z}^{*} - F(x) = d \lambda $.
\end{itemize}
The solutions generated by each method are a subset of the Pareto optimal set.

Before continuing, note that evolutionary algorithms based on the decomposition method have been proposed ~\cite{6600851}, but given the need to blend the decomposition methods with sampling-based path-planning, we do not explore these algorithms further in this paper.

Sampling-based path planning works effectively in continuous space. 
The RRT (Rapidly exploring RandomTtree) has been one of the most popular tools, which  efficiently explores the space by randomly sampling the search space; this algorithm tends to work well in the presence of complex obstacles.
It has been shown that under certain conditions, RRT will fail to find an optimal solution~\cite{Karaman.Frazzoli:RSS10}. 
In response, the RRT$^{*}$ algorithm has been proposed, which uses a \emph{Rewire} process to gradually update the tree structure when new samples of the space indicate that this is needed.
The asymptotic optimality of RRT$^{*}$ has been proven in~\cite{Karaman.Frazzoli:RSS10}~\cite{Karaman:2011:SAO:2000201.2000209}. 
%Figure \ref{fig:RRTstar2} illustrates a tree generated using the RRT* algorithm.
%\begin{figure}
%\centering
%\includegraphics[width=0.9\linewidth]{fig/RRTstar2}
%\caption{Tree structure after exploring fitness space.}
%\label{fig:RRTstar2}
%\end{figure}
In the next section, we present an algorithm that explores the solution space using RRT$^{*}$-based tree structures but uses multiple trees in the spirit of decomposition-based multi-objective optimization.
Because a set of trees are constructed in the exploration process, we call the algorithm MORRF$^{*}$ (Multi-Objective Rapidly exploring Random Forest$^{*}$).


\section{Multi-Objective Rapidly exploring Random Forest$^{*}$}
\label{sec:morrt}

Consider a multi-objective path planning problem defined on a bounded, connected open set $X\subset\mathbb{R}^d$ of possible solutions, and $K$ different objectives $\{f_1(\cdot), f_2(\cdot), ... f_{K}(\cdot)\}$. 
Without loss of generality, we assume that each $f_k(\cdot)$ is a cost function so that our objective is to minimize these functions.  
Since the Pareto optimal set is not enumerable, our {\em goal is to find a representative, finite ($M$-element) subset of the Pareto optimal set}.  
By ``representative" we mean that we want a diverse set of solutions that span the Pareto set rather than, for example, several points clustered in a single region of the Pareto set.  

\begin{defn}{ \textbf{Multi-Objective Path Planning} }
Consider a bounded, connected open set $ X \subset \mathbb{R}^{d} $, an obstacle space $ X_{obs} $, an initial state $ x_{init} $, and a goal region $ X_{goal} $. 
Consider the set of $K$ objectives determined by a vector function $ \vec{F}(\cdot) = [ f_{1} (\cdot), \ldots , f_{K}(\cdot) ]^{T}$ defined by $\vec{F}: \mathbb X \rightarrow \mathbb{R}^{K} $. 
Denote the obstacle-free space by $ X_{\it free} = X \setminus X_{obs} $. Note that $\vec{F}$ is defined for all points in $X$ both those in free space and obstacle space.

Define a {\em path} in $X$ as a continuous curve parameterized by $s$, denoted by $\sigma : [0,s] \rightarrow X$. 
Define the cost of the path as the vector-valued function $ \vec{F}(\sigma) = \int_{\sigma} \vec{F}(x)ds $.  
The goal is to find $ M $ Pareto optimal paths $ \sigma^{*} \in \Sigma^{*}$ such that
\begin{itemize}
	\item $\forall \tau\in[0,s], \sigma^*(\tau) \in X_{\it free}$;
	\item $ \sigma^{*} (0) = x_{init} $ and $ \sigma^{*} (s) = X_{goal}  $;
	\item $ \not \exists \sigma , \forall k \in K, f_{k} (\sigma) > f_{k} (\sigma^{*}) $.
\end{itemize}
\end{defn}
\noindent Note that this last condition enforces a very strict form of payoff dominance; extensions to the algorithm can be made for weaker forms of payoff dominance.

Adopting the idea from the MOEA-D algorithm~\cite{4358754}, the $M$ elements in the solution set $\Sigma^{*}$ will be obtained by decomposing the multi-objective problem into $ M $ subproblems.  
In this paper, we implement only the Tchebycheff approach, noting that the Boundary Intersection Approach can be used with only slight modifications to our algorithm. The Tchebycheff approach requires us to define a ``Utopia" reference vector $ \vec{z}^{*} $ in the fitness space. 
Before describing how we find $ \vec{z}^{*} $ and how we combine the Tchebycheff approach with RRT$^{*}$, it is useful to illustrate how the reference vector is used to help find the Pareto set; Figure~\ref{fig:Tchebycheff} illustrates the process for two objectives.  
\begin{figure}
\centering
\includegraphics[width=0.9\linewidth]{fig/Tchebycheff.pdf}
\caption{Tchebycheff method of finding Pareto front.}
\label{fig:Tchebycheff}
\end{figure}
Recall from the previous section that  $ \vec{\lambda} = [ \lambda_{1} , \cdots , \lambda_{K}  ]^{T} $ is a weighting vector such that $ \sum_{k=1}^{K} \lambda_{k} = 1 $ and that the Tchebycheff approach seeks to find solutions $ x\in X $ that minimize $ g^{te} (x \mid \lambda , \vec{z}^{*}) = \max_{1 \leq k \leq K}  \{ \lambda_{k} | f_{k}(x) - \vec{z}^{*}_{k}  | \} $.  
As illustrated in the Figure, the ``Utopia'' reference vector is defined as that point in reward space that would be obtained if it were possible to find a solution that produced the minimum value for all objectives, that is the $k^{\rm th}$ element of $\vec{z}^*$ is given by $\vec{z}^{*}_{k} = \arg \min_{x \in X} f_{k}(x)$.  
It is called the ``Utopia'' reference vector because it represents the very best that could conceivably be achieved for an ideal point in the solution space.

%{\sc I don't understand the indexing on $g^{te}$, the difference between i and k on the right hand side of $ g^{te} (x \mid \lambda , \vec{z}^{*}) = \max_{i \leq k \leq K}  \{ \lambda_{i} | f_{k}(x) - \vec{z}^{*}_{k}  | \} $.}
%{\sc REPLY: There is some typo. I think now it is clear after corrected. Please see the current statement.}

Given this brief overview of the Tchebycheff method, we now need to extend it to allow for RRT$^{*}$-based sampling of the search space.  
We will need one type of RRT$^{*}$ structure to explore in an attempt to find the ``Utopia'' reference vector in payoff space and another type of RRT$^{*}$ structure to find paths that minimize the Tchebycheff condition.  
Thus, there are two types of tree structures used for the optimization process.
\begin{itemize}
\item Each \emph{reference tree} explores using a single objective $ f_{k} (x), k \in K $. 
The cost of each vertex is calculated using the $ k $-th objective function.
\item Each \emph{subproblem tree} explores a subproblem $ g_{m} ( x \mid \lambda_{m} , \vec{z}^{*} ) , m \in M $.
The cost of each vertex is calculated using $ g_{m}(x) $ defined by the corresponding approach.
\end{itemize}
Thus $ K $ reference trees are used, one each to explore the minimum of each objective, and $ M $ subproblem trees are used, one for each weighting vector, $ \lambda_{m} $, which is described below.  
The $K$ reference trees and $M$ subproblem trees constitute the exploration forest.

We are now in a position to describe the main flow of the MORRF* algorithm; see Algorithm~\ref{alg:rapidly_exploring_process}.  
The first four steps initialize two trees, the reference tree with vertices and edges denoted by $V_r$ and $E_r$, respectively, and the subproblem tree with vertices and edges denoted by $V_s$ and $E_s$, respectively.  
Each reference and subproblem tree are a collection of edges and vertices, $G_r=(V_r,E_r)$ and $G_s=(V_s,E_s)$, respectively, and the collection of reference trees and subproblem trees are denoted by ${\mathbf G}_r = \{G_r: r\in \{1, \ldots, K\}\}$ and ${\mathbf G}_s = \{G_s: s \in \{q, \ldots, M\}$.  

Because this is a path-planning problem, each vertex in each tree corresponds to a physical location in configuration space.  
For the examples used later in this chapter, configuration space is a plane so the distances will all be computed using Euclidean distance. 
Note that each each tree, reference and subproblem, uses the same set of vertices, meaning they all share the same points in configuration space.  
The differences between the trees is the edge set; each reference tree and each subproblem tree has a different way of connecting the vertices.

In each iteration, $i\in\{1, \ldots, N\}$ where $N$ is the maximum number of iterations allowed by the algorithm, a new position, $x_{rand}$ is generated by randomly sampling from the configuration space.  
The set of vertices is then searched to find that vertex whose position in the plane is nearest the random point; since all trees share the same set of vertices, any tree $G\in{\mathbf G}_r \cup {\mathbf G}_s$ may be used to find the nearest point.  
The location of this vertex is labeled $x_{nearest}$.  
It is possible that the distance between the newly sampled position and the vertex nearest to this position is very large.  
A tolerance parameter, $\eta$, is used to guarantee that the distance between the vertices in the tree and the new position is within some exploration tolerance; this is accomplished in the {\sc Steer} method.  
If the distance between $x_{rand}$ and $x_{nearest}$ is less than the tolerance $\eta$, then $x_{new}=x_{nearest}$.  
Otherwise, a line segment between $x_{rand}$ and $x_{nearest}$ is constructed and the point on this line segment that is distance $\eta$ from $x_{nearest}$ becomes the new point $x_{new}$. 
This process of finding $x_{new}$ is represented in the top layer of Figure~\ref{fig:MORRTstar}, with the dashed circle around the new point indicating $\eta$.

\begin{figure}[H]
\centering
\includegraphics[width=0.9\linewidth]{./fig/MORRTstar}
\caption{Rapidly exploring process}
\label{fig:MORRTstar}
\end{figure}

Given the location of a new vertex for each tree, edges are added, potentially different edges for each reference and each subproblem tree.
We require that each new vertex be connected to some existing vertex, so a feasibility check is added using the {\sc ObstacleFree} method.
This method checks whether the line segment connecting $x_{new}$ and $x_{nearest}$ enters obstacle space.
If it does, no new vertices and no new edges are added, and another iteration of the algorithm begins. 
This check guarantees that when the algorithms are called that determine which edge to add to the reference tree or subproblem tree, there is always at least one possible edge that can be added; this is consistent with the RRT* algorithm.

The exploration at each iteration is given in Algorithm \ref{alg:rapidly_exploring_process}.  Like RRT*, when the algorithm stops, each reference tree and subproblem tree returns a path, and the set of all these paths forms the solution set.

\begin{algorithm}
	\begin{algorithmic}[1]
		\For{ \textbf{each} $ V_{r} \in \mathbf{V}_{r} $ } 
		\State $ V_{r} \leftarrow \{ x_{init} \} $; $ E_{r} \leftarrow \emptyset $; $ i \leftarrow 0 $
		\EndFor
		\For{ \textbf{each} $ V_{s} \in \mathbf{V}_{s} $ } 
		\State $ V_{s} \leftarrow \{ x_{init} \} $; $ E_{s} \leftarrow \emptyset $; $ i \leftarrow 0 $
		\EndFor
		\While{ $ i < N $ }
		\For{ \textbf{each} $ G_{r} \in \mathbf{G}_{r} $ } 
		\State $ G_{r} \leftarrow (V_{r}, E_{r}) $
		\EndFor
		\For{ \textbf{each} $ G_{s} \in \mathbf{G}_{s} $ } 
		\State $ G_{s} \leftarrow (V_{s}, E_{s}) $
		\EndFor
		\State $ x_{rand} \leftarrow $ \Call{ Sample }{$ i $} ; $ i \leftarrow i + 1 $
		%\State $ V' \leftarrow V $; $ E' \leftarrow E $
		\State $G$ is any graph from ${\mathbf G}_r\cup {\mathbf G}_s$.
		\State $ x_{nearest} \leftarrow $ \Call{Nearest}{$ G, x_{rand} $}
		\State $ x_{new} \leftarrow $ \Call{Steer}{$ x_{nearest}, x_{rand},\eta $}
		\If{ \Call{ObstacleFree}{$ x_{nearest}, x_{new} $} }
		\For{ \textbf{each} $ G_{r} \in \mathbf{G}_{r} $ } 
		\State $ (V_{r}, E_{r}) \leftarrow $ \Call{ Extend$_{\it Ref}$ }{$ G_{r}, x_{new}, x_{\it nearest}, r$}
		\EndFor
		\For{ \textbf{each} $ G_{s} \in \mathbf{G}_{s} $ } 
		\State $ (V_{s}, E_{s}) \leftarrow $ \Call{ Extend$_{\it Sub}$ }{$ G_{s}, x_{new}, x_{\it nearest},s $}
		\EndFor
		\EndIf
		\EndWhile
	\end{algorithmic}
	\caption{Multi-Objective Rapidly exploring Random Forest$^{*}$ }
	\label{alg:rapidly_exploring_process}
\end{algorithm}

We now define several functions, using appropriately modified definitions from~\cite{Karaman.Frazzoli:RSS10}.
\begin{itemize}
\item \textsc{Sample}():
Returns independent uniformly distributed samples from $ X_{\mbox{free}} $. 
%{\sc *** According to what distribution? ***}
%{\sc ANSWER: I changed to ``uniformly'', hope this answer the question.}

\item \textsc{Nearest}():
Returns a the position of the vertex whose position is closest to point $ x $.
\textsc{Nearest}($ G = (V,E), x $) = $ \arg \min_{v \in V} \lVert x - v \rVert $.
	
\item \textsc{Steer}(): Given two points $ x $ and $ y $, returns a point $ z $ on the line segment from $x$ to $y$ that that is no greater than $eta$ from $y$. 

\textsc{Steer}( $ x,y,\eta $ ) = $ \arg \min_{ z \in \mathbb{R}^{d}, \lVert z -x \rVert \leq \eta } \lVert z - y \rVert $.

\item \textsc{ObstacleFree}(x,x): Returns True if $ [ x, x' ] \subset X_{\it free} $, which means the line segment between $ x $ and $ x' $ lies in $ X_{\it free} $.

\end{itemize}

%Because the convergence of the tree structure in RRT* means that the path from the root to any vertex is an optimal path of the defined cost.
%We use the same sampling position to extend all the trees in one iteration.
%Thus the vertices in the reference trees could be used as reference for estimating the cost in constructing the subproblem trees.

Given the general algorithm, we can now discuss how edges are added to the reference and subproblem trees.  
As illustrated in Figure~\ref{fig:MORRTstar}, second layer, edges to the reference trees are added before the edges to the subproblem trees.  
This allows us to use compute the Utopia reference vector using the path costs for each reference tree, each reference tree returning a path that approximates the minimum cost for a specific objective.  
The Utopia reference vector is then used to determine which edges should be added for each subproblem. Stated another way, the edges added to each tree are determined by the definition of the fitness (cost function) for each tree.

%Like all the sampling-based optimization, the random positions are uniformly sampled from the workspace.
%It means that all the tree have equivalent vertices constructed from same positions set sequentially.
%But they are connected by different measurements of the costs, either a single objective or a cost from subproblem definition.
%The edges of the trees can be different.

Consider the second layer in Figure \ref{fig:MORRTstar}, which shows the exploration process for the reference trees.
When a new position is obtained (red dot in Figure \ref{fig:MORRTstar}), all reference trees add a vertex that corresponds to this new location.  
Each reference tree then connects this new vertex to existing nodes by ``rewiring" a set of neighboring vertices within a specified radius (red dash circle in Figure \ref{fig:MORRTstar}).  
The process of rewiring consists of adding edges between existing vertices and the new vertex.  This is done using the {\sc Extend} method, given in Algorithm~\ref{alg:morrtstar:extend:ref}.

The idea of the algorithm is to add the new vertex, $x_{\it new}$ to the graph and then look for existing vertices in the graph that are close to the new vertex. 
Line~1 checks to see if the randomly generated position is precisely on top of the position of a vertex already in the graph.  
If so, no edges are added to the graph; this prevents self-loops, and is necessary because of finite precision numerical representations.  

Otherwise, the new vertex is added to the graph and all vertices in the graph within a particular radius are identified.  
The radius is determined by the current number of vertices in the graph. 
The radius and volume are precisely defined in the {\sc Near} method, given below. 
{\sc Walter, Give some intuition about why this equation is used, and give a reference if needed.  I think it is an estimate of the expected density of the nodes in the graph, given as a spatial distribution in $d$-dimensions.}  
{\sc Answer: This is the essence of RRT*. It guarantees the convergence of the cost.}


Because of the way that $x_{new}$ is defined, we are guaranteed that $|X_{near}| \geq 1$, that is, there is at least one vertex ``near'' the new position.

Lines~5-10 then find the vertex, $x_{min}$ that produces the minimum obstacle-free cost adds the edge between $x_{min}$ and $x_{new}$ to the graph.  
Because of the check in in Algorithm~\ref{alg:rapidly_exploring_process}, there is always at least one such edge.  
Observe that this cost is computed using the $k^{\rm th}$ cost function, which is, after all, the role of the reference tree.

Lines~11-17 ``rewire'' the graph.  
This only occurs if there are more than two vertices in the neighborhood of $x_{new}$.  
The lines step through every vertex $x_{near}$ in the neighborhood (other than the minimum cost vertex -- see line~11) and compares (a)~the cost of the current path through the tree to $x_{near}$ to (b)~the cost of the same path to the parent $x_{parent}$ of $x_{near}$ plus the cost from $x_{parent}$ to the new node $x_{new}$. 
If the cost of the path to $x_{new}$ is less than the cost of the path to $x_{near}$, the tree is rewired so that the parent forgets $x_{near}$ and connects instead to $x_{new}$ -- see lines~16-17.

\begin{algorithm}[hbtp]
\begin{algorithmic}[1]
\If{ $ x_{new} = x_{nearest} $} 
	\Return $G=(V,E)$ 
\EndIf
\State $ V' \leftarrow V \cup \{ x_{new} \} $
\State $ x_{min} \leftarrow x_{nearest} $
\State $ X_{near} \leftarrow $ \Call{Near}{$ G, x_{new}, | V | $}
%\If{ $ x_{new} \neq x_{min} $ }
	\For{\textbf{each} $ x_{near} \in X_{near} $ }
		\If{ \Call{ObstacleFree}{$ x_{new} , x_{near} $} }
			\State $ c_{k}' \leftarrow $ \Call{Cost$_{k}$}{$ x_{near} $} $ + c_{k}( $ \Call{Line}{$ x_{near}, x_{new} $} $ ) $ 
			\If{ $ c_{k}' < $ \Call{Cost$_{k}$}{$ x_{new} $} }
			\State $ x_{min} \leftarrow x_{near} $
			\EndIf
		\EndIf
	\EndFor
	\State $ E' \leftarrow E' \cup \{ ( x_{min}, x_{new} ) \} $
%\EndIf
\For{\textbf{each} $ x_{near} \in X_{near} \setminus \{ x_{min} \} $ }
	\If{\Call{ObstacleFree}{$ x_{new} , x_{near} $}}
	    \State $ c_{k}' \leftarrow $ \Call{Cost$_{k}$}{$ x_{new} $} $ + c_{k}( $ \Call{Line}{$ x_{new}, x_{near} $} $ ) $ 
	    \If{ $ c_{k}' < $ \Call{Cost$_{k}$}{$ x_{near} $} }
			\State $ x_{parent} \leftarrow $ \Call{Parent}{$ x_{near} $}
			\State $ E' \leftarrow E' \setminus \{ ( x_{parent}, x_{near} ) \} $
			\State $ E' \leftarrow E' \cup \{ ( x_{new}, x_{near} ) \} $
		\EndIf
	\EndIf
\EndFor
\Return $ G' = (V', E') $ 
\end{algorithmic}
\caption{ \textsc{Extend}$_{\it Ref} $ ($ G, x_{\it new}, x_{\it nearest},k$) }
\label{alg:morrtstar:extend:ref}
\end{algorithm} 

The precise definitions of the methods used in the Algorithm~\ref{alg:morrtstar:extend:ref} are given below.
\begin{itemize}
	\item \textsc{Near}($ G, x, \eta $) returns a set of all vertices within the closed ball of radius $ r_{n} $ centered at $ x $, in which $ r_{n} = \min \{ ( \frac{\gamma}{\xi_{d}} \frac{\log n}{n} )^{1/d}  , \eta \} $.
	The volume of the ball is $ \min \{ \gamma \frac{\log n}{n} , \xi_{d} \eta^{d} \} $.

	\item \textsc{Line}($ x, x' $) $ : [0, s] \leftarrow X_{\it free} $ denotes the path defined by line segment from $x$ to $x'$.
	%$ \forall \tau \in [0, s], \sigma( \tau ) = \tau x + (s - \tau) x', s = \lVert x' -x \rVert $.
	{\sc Walter, I tried to simplify this equation and description.  Let me know if you buy it.  If not, the original description is commented in the .tex.}
	
	\item \textsc{Cost}($ v  $) is defined by the cost of the unique path (because $G$ is a tree) from $ x_{ \mbox{init} } $ to a vertex $ v \in V $. \textsc{Cost}($ x_{ \mbox{init} } $) = $ 0 $.
\end{itemize}

{\sc I've refactored Algorithm~3 to match Algorithm~2. The first thing to do will be to remind people of how we compute the Utopia point in payoff space.  Then we need to describe how the weight vector $lambda_G$ is obtained.}

Consider the third layer in Figure~\ref{fig:MORRTstar}, which illustrates how the subproblem trees ``rewire'' to connect to the new vertex.  
The Utopia reference vector, $\vec{c}^*$ is defined as the $k$-dimensional vector constructed from each reference tree.  
The minimum cost path from the starting vertex over all the leaf node is  computed for each reference tree.  
The Utopia reference vector is the vector of these costs. 
Using the Utopia reference vector, each subproblem tree connects its new vertex and rewire a set of neighboring vertices in a radius as well. 
Algorithm \ref{alg:morrtstar:extend:sub} precisely follows Algorithm~\ref{alg:morrtstar:extend:ref} except that instead of computing the cost using one of the objectives, the cost is computed using the Tchebycheff method; each of the $m$ subproblem trees corresponds to a different weighting vector~$\lambda_m$.  
This is performed using the {\sc Fitness} method.

\begin{algorithm}[hbtp]
\begin{algorithmic}[1]
\If{ $ x_{new} = x_{nearest} $} 
	\Return $G=(V,E)$ 
\EndIf
\State $ V' \leftarrow V' \cup \{ x_{new} \} $
\State $ x_{min} \leftarrow x_{nearest} $
\State $ X_{near} \leftarrow $ \Call{Near}{$ G, x_{new}, | V | $}
%\If{ $ x_{new} \neq x_{min} $ }
	\For{\textbf{each} $ x_{near} \in X_{near} $ }
		\If{ \Call{ObstacleFree}{$ x_{new} , x_{near} $} }
			\State $ \vec{c}' \leftarrow $ \Call{Cost}{$ x_{near} $} $ + \vec{c}( $ \Call{Line}{$ x_{near}, x_{new} $} $ ) $ 
			\State $ \eta' =  $ \Call{Fitness}{ $ \vec{c}' , \vec{c}^{*} \mid \lambda_{m} $ }
			\State $ \vec{c}_{new} = $ \Call{Cost}{$ x_{new} $} 
			\State $ \eta_{new} = $ \Call{Fitness}{ $ \vec{c}_{new} , \vec{c}^{*} \mid \lambda_{m} $ }
			\If{ $ \eta' < \eta_{new} $ }
				\State $ x_{min} \leftarrow x_{near} $
			\EndIf
		\EndIf
	\EndFor
	\State $ E' \leftarrow E' \cup \{ ( x_{min}, x_{new} ) \} $
%\EndIf
\For{\textbf{each} $ x_{near} \in X_{near} \setminus \{ x_{min} \} $ }
	\If{\Call{ObstacleFree}{$ x_{new} , x_{near} $} }
		\State $ \vec{c}' \leftarrow $ \Call{Cost}{$ x_{new} $} $ + \vec{c}( $ \Call{Line}{$ x_{new}, x_{near} $} $ ) $ 
		\State $ \eta' =  $ \Call{Fitness}{ $ \vec{c}' , \vec{c}^{*} \mid \lambda_{m} $ }
		\State $ \vec{c}_{near} = $ \Call{Cost}{$ x_{near} $} 
		\State $ \eta_{near} = $ \Call{Fitness}{ $ \vec{c}_{near} , \vec{c}^{*} \mid \lambda_{m} $ }
		\If{ $ \eta' < \eta_{near} $ }
			\State $ x_{parent} \leftarrow $ \Call{Parent}{$ x_{near} $}
			\State $ E' \leftarrow E' \setminus \{ ( x_{parent}, x_{near} ) \} $
			\State $ E' \leftarrow E' \cup \{ ( x_{new}, x_{near} ) \} $
		\EndIf
	\EndIf
\EndFor
\Return $ G' = (V', E') $ 
\end{algorithmic}
\caption{ \textsc{Extend}$_{\it Sub} $ ($ G, x_{\it new}, x_{\it nearest},m$) }
\label{alg:morrtstar:extend:sub}
\end{algorithm} 

{\sc Walter, Please give the equation for the Fitness method.  Also, please describe how the different $\lambda_m$ are obtained.  I assume that the $\lambda_m$ are selected so that you uniformly sample the range of possible weightings.}
{\sc \underline  
(1) The $ \lambda_{m} $ can either be evenly sampled 
or uniformly randomly sampled from the normalized $ K $ space.
In 2-objective problem, I just directly evenly collect values .
In 3-objective problem, I do uniformly randomly sampling.
This is the same with how $ \lambda_{m} $ is obtained in MOEA-D.
(2) The fitness is calculated by one of the three methods in section "Related work".
For example, if I use Tchebycheff approach,
I will firstly calculate $ | f_k(x) - z^{*}_{k} | $ for each objective, multiple it with $ k $th value of the vector $ \lambda_m $.
The maximum of the $ K $ values will be the fitness.
This converts the cost vector ($ K $-dimension) into a single dimension fitness.
Thus, I use FITNESS to differentiate with COST.
}

{\sc This is where I quit for the day.}

\section{Analysis}
\label{sec:theoretic_analysis}

Before we start the analysis, several assumptions need to be inherited from  RRT$^{*}$~\cite{Karaman.Frazzoli:RSS10}.
\begin{asmp}{(Additivity of the objective functions)}
\label{asmp:additivity}	
For all $ k \in K $, $ \sigma_{1} , \sigma_{2} \in X_{\it free} $,
$ c_{k} ( \sigma_{1}  \mid \sigma_{2} ) = c_{k} ( \sigma_{1} ) + c_{k} ( \sigma_{2} ) $.
\end{asmp}

\begin{asmp}{(Continuity of the objective functions)}
\label{asmp:continuity}
For all $ k \in K $, the cost function $ c_{k} $ is Lipschitz continuous,
$ \forall \sigma_{1} : [ 0, s_{1} ] \rightarrow X_{\it free}, \sigma_{2} : [0, s_{2} ] \rightarrow X_{\it free} $,
$ \exists k $ such that 
$ | c_{k} ( \sigma_{1} ) - c_{k} ( \sigma_{2} ) | \leq k \sup_{\tau \in [0,1]} \lVert \sigma_{1} (\tau s_{1}) - \sigma_{2} (\tau s_{2}) \rVert $
\end{asmp}

\begin{asmp}{(Obstacle spacing)}
\label{asmp:spacing}
There exists a constant $ \delta \in \mathbb{R}_{+} $ such that $ \forall x \in X_{\it free} $ , $ \exists x' \in X_{\it free} $ such that
\begin{itemize}
\item the $ \delta $-ball centered at $ x' $ lies inside $ X_{\it free} $;
\item $ x $ lies inside the $ \delta $-ball centered at $ x' $.
\end{itemize}
\end{asmp}

We also assume that two vertices in a tree won't be infinitely close.
From the implementation perspective, it means that the processor has finite precision in calculation.
We have Assumption \ref{asmp:finite_accuracy}.
\begin{asmp}{(Finite accuracy)}
\label{asmp:finite_accuracy}
When $ \lVert x_{1} - x_{2} \rVert \leq \epsilon $, $ x_{1} = x_{2} $.
\end{asmp}
When the distance between the new position and any vertex in the tree is less than $ \epsilon $ (system accuracy), the new position will be considered as equivalent to the position of that vertex.
In Algorithm 2 and Algorithm 3, a new position won't be added to a tree if its distance to some vertex in the tree is less than $ \epsilon $.
It only triggers a ``rewire'' process for a set of near vertices.

We firstly need to show that the tree structure in MORRF$^{*}$ has a finite maximum depth,
so that we can guarantee that all the paths from the tree structure have finite length.
We have Lemma \ref{lem:tree:finite_depth}.

\begin{lem}
\label{lem:tree:finite_depth}
Either the reference tree or the subproblem tree has a finite maximum depth as $ i \rightarrow \infty $.
\begin{proof}
By Assumption \ref{asmp:finite_accuracy}, we know that the distance between two vertices cannot be infinitely small, which are always bigger than or equal to $ \epsilon $.
By the Lipschitz continuity in Assumption \ref{asmp:continuity}, the cost between any two vertices won't be infinitely small as well.
In this case, in a finite working space, the cost of a path will be infinite only when there is a loop in the path.
The cost of the loop is added repeated in calculating the cost of the path.
Assume that the maximum depth of the tree is infinite.
It means that there exists a path that from a position to the start, the cost of which is infinite.
It also equals to that there exist a loop in such a path.
However, this contradicts the property of the tree structure. 
Because in a tree structure, there exists no loop in any path from the root (the start) to any vertex.
Thus, we can state that the reference tree or the subproblem tree constructed from a sampling process has a finite maximum depth.
\end{proof}
\end{lem}

Because all the paths in MORRF$^{*}$ has a finite length.
It means that all the solutions from MORRF$^{*}$ can be converted into a point in a finite high-dimension space.
Therefore, we can import the Techbycheff method in solving such a multi-objective optimization problem~\cite{4358754}~\cite{miettinen1999nonlinear}.
We have Lemma \ref{lem:moo-d:rrt}.

\begin{lem}
\label{lem:moo-d:rrt}
The solutions of MORRF$^{*}$ can be mapped into points in a finite high-dimension space.
\begin{proof}
Let $ \mbox{maxDepth}(G_{ref}^{k}) $ be the maximum depth of $ k $-th reference tree.
Let $ \mbox{maxDepth}(G_{sub}^{m}) $ be the maximum depth of $ m $-th subproblem tree.
We have $ \mbox{maxDepth}(G_{ref}) = \max_{k = 1 , \cdots , K} ( \mbox{maxDepth}(G_{ref}^{k}) ) $ and $ \mbox{maxDepth}(G_{sub}) = \max_{m = 1 , \cdots , M} ( \mbox{maxDepth}(G_{sub}^{m}) ) $.
Thus let 
 $ \bar{N}_{MD} = \max \left(  \mbox{maxDepth}(G_{ref}), \mbox{maxDepth}(G_{sub}) \right) $.
It means that the segment number of any path from MORRF$^{*}$ can be less than $ \bar{N}_{MD} $.

Therefore, any path from MORRF$^{*}$ can be converted into an equivalent path of $ \bar{N}_{MD} $ segments by repeating some vertex before moving to the next one.
For example, duplicating $ x_{2} $ in $ (x_{1} , x_{2}, x_{3} ) $ makes an equivalent path of length $ 4 $ , $ (x_{1} , x_{2},  x_{2}, x_{3} ) $.
The cost will not be changed, $ f( (x_{1} , x_{2}, x_{3}) ) = f( (x_{1} , x_{2},  x_{2}, x_{3} ) )$.
Using a space of dimension $ \bar{N}_{MD} $, any solution from MORFF$^{*}$ can be mapped into a point in the same space.
Let the dimension of the working space be $ N_{dim} $.
We can consider that MORRF$^{*}$ searches the Pareto optimal set in a $ \bar{N}_{MD} * N_{dim} $ dimension space.
\end{proof}
\end{lem}

\begin{comment}
\begin{lem}
\label{lem:moo-d:rrt}
MORRF$^{*}$ can be modeled as a 
The decomposition method is applicable to the sampling-based path planning.
\begin{proof}
In a sampling-based path planning problem, let $ N_{i} $ be the number of samplings at iteration $ i $.
In the cost minimization problem, assume there is no loop in a path, which means that a path will not visit a visited vertex.
As a path $ \sigma $ is a sequence of vertices, the maximum size of a path is less than $ N_{i} $, i.e.
$ | \sigma | \leq N_{i} $.
Let $ \bar{i} $ be the stopping iteration number.
The number of vertices in any path is less than $ N_{ \bar{i} } $, which can be represented as a path of length $ N_{ \bar{i} } $ by duplicating the vertices in a path.
For example, duplicating $ x_{2} $ in $ (x_{1} , x_{2}, x_{3} ) $ makes an equivalent path of length $ 4 $ , $ (x_{1} , x_{2},  x_{2}, x_{3} ) $.
The cost will not be changed, $ f( (x_{1} , x_{2}, x_{3}) ) = f( (x_{1} , x_{2},  x_{2}, x_{3} ) )$.
Using a space of dimension $ N_{ \bar{i} } $, any path $ \sigma $ in a sampling-based path planning problem can be mapped into a point in the same space.
The decomposition methods mentioned in \cite{4358754} can be imported in this case.		
\end{proof}
\end{lem}
\end{comment}

\begin{figure}
\centering
\includegraphics[width=0.7\linewidth]{fig/dependency}
\caption{The dependency of the trees in MORRF$^{*}$.}
\label{fig:dependency}
\end{figure}

Lemma \ref{lem:moo-d:rrt} tells us that the multi-objective path planning could be decomposed into a set of subproblems.
In MORRF$^{*}$, the responsibility of a subproblem tree is to find the optimal solution of its subproblem.
The next question needs to be answered is that whether the subproblem tree could find the optimal solution of its subproblem.

We notice that the \textsc{Extend} process in RRT$^{*}$ is not goal-oriented.
Let $ z^{*}(x) $ be the minimum cost from the start to the position of vertex $ x $.
We can generalize the conclusion of Theorem 22 in \cite{Karaman.Frazzoli:RSS10} to all the vertices in the RRT$^{*}$.
\begin{lem}
\label{lem:tree_vex:conv}
When Assumption \ref{asmp:additivity}, \ref{asmp:continuity} and \ref{asmp:spacing} hold,
the cost of the minimum cost path from the root to any vertex in RRT$^{*}$ converges to the optimal cost almost surely, i.e.,
$
P( \{ \lim_{ i \rightarrow \infty } c(x, i)  = z^{*}(x) \} ) = 1, x \in V $.
\begin{proof}
%The construction of RRT* is not goal-oriented.
%The ``rewire'' process potentially will update all the vertices and converge the value to the optimal one.
%Similar with that of a goal vertex, the paths from the root to all other vertices will converge to corresponding optimal ones as well.
The asymptotic optimality of RRT$^{*}$ does not rely on how the sampling process is like (Theorem 22, \cite{Karaman.Frazzoli:RSS10}), though the convergence rate might be different.
Simply changing the goal to the position of any vertex still hold the asymptotic optimality.
Thus, we could generalize the asymptotic optimality from the goal to all the vertices.
\end{proof}
\end{lem}

The solve of a subproblem depends on a correct estimation of the reference vector $ \vec{z}^{*} $.
Thus, we need to have the solutions of all the reference trees converging to the optimal firstly.
The construction of a reference tree does not depend on any other tree.
Thus, the construction process is equivalent to the construction of a RRT*.
The asymptotic optimality of RRT* in Lemma \ref{lem:tree_vex:conv} is inherited here.
Thus the cost of the solution converges to the optimal of single objective.
\begin{lem}
\label{lem:ref_tree:conv}
When Assumption \ref{asmp:additivity}, \ref{asmp:continuity} and \ref{asmp:spacing} hold,
the cost of the minimum cost path from the root to any vertex in $ k $-th reference tree converges to $ z^{*}_{k} $ almost surely, i.e., 
$ P( \{ \lim_{ i \rightarrow \infty }  c_{k} (x, i ) = z^{*}_{k} (x) \} ) = 1  $.
\end{lem}

Then we need to show that after all the reference trees converge to the structure that provides optimal cost, 
the subproblem tree can also converge to the structure that provides optimal fitness $ g^{*}_{m} ( x \mid \lambda_{m} , z^{*} ) $.
\begin{lem}
\label{lem:sub_tree:conv}
When Assumption \ref{asmp:additivity}, \ref{asmp:continuity} and \ref{asmp:spacing} hold,
with $ \vec{z}^{*} (x) $ for any $ x $ given,
the cost of the solution of $ m $-th subproblem tree converges to the optimal cost of the $ m $-th subproblem, i.e.,
$
P( \{ \lim_{ i \rightarrow \infty } c_{ \lambda_{m} }( i ) \} ) = z^{*}_{ \lambda_{m} }
$
\begin{proof}
When the reference vector $ \vec{z}^{*}(x) $ converges, the cost of the minimum cost path from the root to the vertex of position $ x $ in $ m $-th subproblem tree will gradually converge to the optimal by Lemma \ref{lem:tree_vex:conv}.
It means that the minimum fitness path from the root to any vertex in a subproblem tree will converge to an optimal minimum fitness path, in which the vertices in goal region are included.
It equals to that the cost of the solution of $ m $-th subproblem tree converges to the optimal cost of the $ m $-th subproblem.
%The construction of a subproblem tree depends on the convergence of all the reference trees.
%When all the reference trees have converged, the correct reference values $ c^{*} (x) $ of all the vertices could be obtained.
%The convergence process will be similar with that of a single RRT*.
%By Lemma \ref{lem:ref_tree:conv} and Lemma \ref{lem:sub_tree:conv}, we know that the utopia reference value $ c^{*} (x) $ could be correctly estimated after all the reference trees have reached optimality.
\end{proof}
\end{lem}

Now, we can prove that the solutions from MORRF$^{*}$ almost surely converges to a subset of the Pareto optimal set.

\begin{thm}
\label{thm:morrt:conv}
When Assumption \ref{asmp:additivity}, \ref{asmp:continuity} and \ref{asmp:spacing} hold,
the solutions from MORRF$^{*} $ converges to a subset of the Pareto optimal set almost surely, i.e.
$
P( \lim_{ i \rightarrow \infty }  \Sigma^{\mbox{MORRF}^{*}}_{i}  \subset \Sigma^{*} ) = 1.
$
\begin{proof}
As the solutions of MORRF$^{*}$ can be modeled in points in a high-dimension space by Lemma \ref{lem:moo-d:rrt}, the Tchebycheff method could be imported to decompose the multi-objective optimization problem into a set of subproblems.
By the fitness definition of the subproblem trees, if the subproblem tree could find a solution that minimize the fitness, the solution is in the Pareto optimal set of the multi-objective optimization problem.

Lemma \ref{lem:ref_tree:conv} guarantees that the reference vector $ \vec{z}^{*}(x) $ at any location $ x $ converges to the correct estimation after running enough iteration.
Thus, by Lemma \ref{lem:sub_tree:conv}, we have that the solution cost of the $ m $-th subproblem tree converges to $ z^{*}_{ \lambda_{m} } $.
It means that the solution converges to an optimal solution to $ m $-th subproblem as the iteration goes.
Therefore, the set of the solutions from all the subproblem trees converge to a subset of the Pareto optimal set, as the iteration goes~\cite{4358754}~\cite{miettinen1999nonlinear}.
\end{proof}
\end{thm}

\section{Simulation}
\label{sec:simulation}

\begin{comment}
2D (weighted sum + Tchebycheff method)
2D (With obstacles)
3D
compare NSGA-II
\end{comment}

We now present a series of simulation studies that provide evidence that MORFF* produces a representative set of samples from the Pareto set.
Results from MORFF* are obtained for path-planning problems with two objectives and three objectives, and are compared to a modified version of the NSGA-II multi-objective path-planning algorithm~\cite{Ahmed2013} as well as a variant of MORFF* that uses a weighted sum rather than the Tchebycheff approach.
NSGA-II was selected because evidence suggests that it provides more uniform samples from the Pareto set than other approaches~\cite{deb2002fast}.  
We modified the NSGA-II algorithm for this problem to use paths as inputs, represented by a series of waypoints connected by line segments;he cost calculation is identical with that in  MORRF$^{*}$, calling \textsc{Line}($ x_{1}, x_{2} $) to calculate the cost between two way points $ x_{1} $ and $ x_{2} $.  
The weighted sum approach was chosen because evidence suggests that it works well only when all the objectives are convex~\cite{4358754} whereas the Tchebycheff approach should bring better diversity in the solutions~\cite{4358754}.  
The weighted sum approach uses the same sampling method for weights as that used to generate the $\lambda_i$ in MORFF*.
Each method was run for $ 5000 $ iterations and restricted to $ 30 $ solutions.  

The first simulation study compares there three algorithms in an obstacle-free world with two objectives: 
minimize Euclidean distance, see Figure~\ref{fig:sim:norm:distance}, and minimize a cost function, see Figure~\ref{fig:sim:norm:fitness1}, which has dark colors as low costs and light colors as high costs.  


The first thing to note is that the convergence of NSGA-II-based path-planning is very slow.
This is indicated in Figures~\ref{fig:sim:norm:pf:a}-\ref{fig:sim:norm:sols:a}, which show the approximation to the Pareto set and corresponding paths, respectively, after $5000$ iterations; observe how the quality of the paths and sampling of the Pareto set is uneven and unsatisfactory.
By contrast, the weighted sum approach returns a set of high-quality solutions close to the Pareto optimal set, see Figures~\ref{fig:sim:norm:pf:b} and \ref{fig:sim:norm:sols:b}; especially note the difference in x-axis values (corresponding to the costs of the paths) between the solutions from NSGA-II and the MORFF* using weighted sum.
Finally, note the somewhat uneven clustering of solutions on Pareto front for MORFF* using weighted sum, and compare this to the slightly more uniform clustering of MORFF* using the Tchebycheff approach in Figures~\ref{fig:sim:norm:pf:c}-\ref{fig:sim:norm:sols:c}.

%{\sc Need figures c, e, and g to have bigger axis labels.  Actually, all the Pareto front axes need to have bigger labels.}

\begin{figure}[tb]
	\centering
	\begin{subfigure}[b]{0.45\linewidth}
		\centering
		\includegraphics[width=\textwidth]{fig/sim2-2obj/MORRTstar00-0.png}
		\caption{Minimize distance}
		\label{fig:sim:norm:distance}
	\end{subfigure}
	\begin{subfigure}[b]{0.45\linewidth}
		\centering
		\includegraphics[width=\textwidth]{fig/sim2-2obj/MORRTstar00-1.png}
		\caption{Minimize cost 1}
		\label{fig:sim:norm:fitness1}
	\end{subfigure}  \\
	\begin{subfigure}[b]{0.45\linewidth}
		\centering
		\includegraphics[width=\textwidth]{fig/sim3-2obj/PF03-MOPATH.pdf}
		\caption{Pareto set: NSGA-II}
		\label{fig:sim:norm:pf:a}
	\end{subfigure}
	\begin{subfigure}[b]{0.45\linewidth}
		\centering
		\includegraphics[width=\textwidth]{fig/sim3-2obj/MOPath01-ALL.png}
		\caption{Pareto paths: NSGA-II}
		\label{fig:sim:norm:sols:a}
	\end{subfigure}  \\
	\begin{subfigure}[b]{0.45\linewidth}
		\centering
		\includegraphics[width=\textwidth]{fig/sim1-2obj/PF01-MORRT.pdf}
		\caption{Pareto set: weighted sum}
		\label{fig:sim:norm:pf:b}
	\end{subfigure}
	\begin{subfigure}[b]{0.45\linewidth}
		\centering
		\includegraphics[width=\textwidth]{fig/sim1-2obj/MORRTstar00-ALL.png}
		\caption{Pareto paths: weighted sum}
		\label{fig:sim:norm:sols:b}
	\end{subfigure}  \\
	\begin{subfigure}[b]{0.45\linewidth}
		\centering
		\includegraphics[width=\textwidth]{fig/sim2-2obj/PF02-MORRT2.pdf}
		\caption{Pareto set: Tchebycheff}
		\label{fig:sim:norm:pf:c}
	\end{subfigure} 
	\begin{subfigure}[b]{0.45\linewidth}
		\centering
		\includegraphics[width=\textwidth]{fig/sim2-2obj/MORRTstar00-ALL.png}
		\caption{Pareto paths: Tchebycheff}
		\label{fig:sim:norm:sols:c}
	\end{subfigure}
	\caption{Path planning with two objectives.}
	\label{fig:sim:norm}
\end{figure}

Recall that the weighted sum approach is designed to work well for convex sets and the Tchebycheff approach is designed to give more uniform sampling for non-convex sets. 
We therefore compared results for the two approaches for an environment with obstacles, omitting results for NSGA-II because convergence is so slow.  
The results are shown in Figure \ref{fig:sim:obs}.
As before, observe that the Tchebycheff approach yields a more uniform sampling, albeit one that appears to be somewhat noisy approximation to the Pareto set.

\begin{figure}[tb]
	\centering
	\begin{subfigure}[b]{0.45\linewidth}
		\centering
		\includegraphics[width=\textwidth]{fig/sim4-obstacle/MORRTstar01-1-0.png}
		\caption{Minimize distance}
		\label{fig:sim:obs:distance}
	\end{subfigure}
	\begin{subfigure}[b]{0.45\linewidth}
		\centering
		\includegraphics[width=\textwidth]{fig/sim4-obstacle/MORRTstar01-1-1.png}
		\caption{Minimize cost 1}
		\label{fig:sim:obs:fitness1}
	\end{subfigure}  \\
	\begin{subfigure}[b]{0.45\linewidth}
		\centering
		\includegraphics[width=\textwidth]{fig/sim4-obstacle/PF04-MORRT.pdf}
		\caption{Paretoset: weighted sum}
		\label{fig:sim:obs:pf:a}
	\end{subfigure}
	\begin{subfigure}[b]{0.45\linewidth}
		\centering
		\includegraphics[width=\textwidth]{fig/sim4-obstacle/MORRTstar01-1-ALL.png}
		\caption{Pareto paths: weighted sum}
		\label{fig:sim:obs:sols:a}
	\end{subfigure}  \\
	\begin{subfigure}[b]{0.45\linewidth}
		\centering
		\includegraphics[width=\textwidth]{fig/sim5-obstacle/PF05-MORRT2.pdf}
		\caption{Pareto set: Tchebycheff}
		\label{fig:sim:obs:pf:b}
	\end{subfigure} 
	\begin{subfigure}[b]{0.45\linewidth}
		\centering
		\includegraphics[width=\textwidth]{fig/sim5-obstacle/MORRTstar01-1-ALL.png}
		\caption{Pareto paths: Tchebycheff}
		\label{fig:sim:obs:sols:b}
	\end{subfigure}
	\caption{Path planning with two objectives and an obstacle.}
	\label{fig:sim:obs}
\end{figure}

We then tested the MORFF* algorithms on a two-objective problem  in which there exists a conflict in the costs; 
see Figures~\ref{fig:sim:nonconvex:fitness1}-\ref{fig:sim:nonconvex:fitness2}. 
The results illustrated in Figure~\ref{fig:sim:nonconvex} illustrate that, once again, the Tchebycheff approach shows better diversity but is somewhat more noisy than the weighted sum approach in Figure \ref{fig:sim:nonconvex}.

\begin{figure}[tb]
	\centering
	\begin{subfigure}[b]{0.45\linewidth}
		\centering
		\includegraphics[width=\textwidth]{fig/sim8-nconvex/MORRTstar03-0.png}
		\caption{Minimize cost 1}
		\label{fig:sim:nonconvex:fitness1}
	\end{subfigure}
	\begin{subfigure}[b]{0.45\linewidth}
		\centering
		\includegraphics[width=\textwidth]{fig/sim8-nconvex/MORRTstar03-1.png}
		\caption{Minimize cost 2}
		\label{fig:sim:nonconvex:fitness2}
	\end{subfigure}  \\
	\begin{subfigure}[b]{0.45\linewidth}
		\centering
		\includegraphics[width=\textwidth]{fig/sim8-nconvex/PF03-MORRT.pdf}
		\caption{Pareto set: weighted sum}
		\label{fig:sim:nonconvex:pf:a}
	\end{subfigure}
	\begin{subfigure}[b]{0.45\linewidth}
		\centering
		\includegraphics[width=\textwidth]{fig/sim8-nconvex/MORRTstar03-ALL.png}
		\caption{Pareto paths: weighted sum}
		\label{fig:sim:nonconvex:sols:a}
	\end{subfigure}  \\
	\begin{subfigure}[b]{0.45\linewidth}
		\centering
		\includegraphics[width=\textwidth]{fig/sim9-nconvex/PF03-MORRT2.pdf}
		\caption{Pareto set: Tchebycheff}
		\label{fig:sim:nonconvex:pf:b}
	\end{subfigure} 
	\begin{subfigure}[b]{0.45\linewidth}
		\centering
		\includegraphics[width=\textwidth]{fig/sim9-nconvex/MORRTstar03-ALL.png}
		\caption{Pareto paths: Tchebycheff}
		\label{fig:sim:nonconvex:sols:b}
	\end{subfigure}
	\caption{Path planning with two conflicting objectives.}
	\label{fig:sim:nonconvex}
\end{figure}

Finally, we evaluated how MORRF$^{*}$ performs three objectives: 
Euclidean distance and the two other objectives are shown in Figures~\ref{fig:sim:many:distance}-\ref{fig:sim:many:fitness2}.
As shown in Figure \ref{fig:sim:many}, the Pareto front uses the Utopia reference vector (Green point) to better approximate the Pareto set than the weighted sum approach, albeit in a somewhat noisy way.

\begin{figure}[tb]
	\centering
	\begin{subfigure}[b]{0.31\linewidth}
		\centering
		\includegraphics[width=\textwidth]{fig/sim6-3obj/MORRTstar02-0.png}
		\caption{Distance}
		\label{fig:sim:many:distance}
	\end{subfigure}
	\begin{subfigure}[b]{0.31\linewidth}
		\centering
		\includegraphics[width=\textwidth]{fig/sim6-3obj/MORRTstar02-1.png}
		\caption{Cost 1}
		\label{fig:sim:many:fitness1}
	\end{subfigure}
	\begin{subfigure}[b]{0.31\linewidth}
		\centering
		\includegraphics[width=\textwidth]{fig/sim6-3obj/MORRTstar02-2.png}
		\caption{Cost 2}
		\label{fig:sim:many:fitness2}
	\end{subfigure}  \\
	\begin{subfigure}[b]{0.45\linewidth}
		\centering
		\includegraphics[width=\textwidth]{fig/sim6-3obj/PF06-MORRT.pdf}
		\caption{Pareto set: weighted sum}
		\label{fig:sim:many:pf:a}
	\end{subfigure}
	\begin{subfigure}[b]{0.45\linewidth}
		\centering
		\includegraphics[width=\textwidth]{fig/sim6-3obj/MORRTstar02-ALL.png}
		\caption{Pareto paths: weighted sum}
		\label{fig:sim:many:sols:a}
	\end{subfigure}  \\
	\begin{subfigure}[b]{0.45\linewidth}
		\centering
		\includegraphics[width=\textwidth]{fig/sim7-3obj/PF07-MORRT2.pdf}
		\caption{Pareto set: Tchebycheff}
		\label{fig:sim:many:pf:b}
	\end{subfigure} 
	\begin{subfigure}[b]{0.45\linewidth}
		\centering
		\includegraphics[width=\textwidth]{fig/sim7-3obj/MORRTstar02-ALL.png}
		\caption{Pareto paths: Tchebycheff}
		\label{fig:sim:many:sols:b}
	\end{subfigure}
	\caption{Path planning with three objectives.}
	\label{fig:sim:many}
\end{figure}

\section{Conclusion} 
\label{sec:conclusion}

This paper presented the MORRF$^{*}$ algorithm for the multi-objective path-planning problems on continuous spaces.
The algorithm blends principles from the RRT* algorithm with principles from multi-objective optimization to produce an algorithm that provides a reasonable approximation of the Pareto set, outperforms a common multi-objective optimization problem on a path-planning problem, and has guaranteed best-case performance.

Future work should extend the algorithm to include not only the weighted sum and Tchebycheff approach but also the the boundary intersection approach, which results from~\cite{4358754} suggest should have even better diversity.
MORRF* could also be made more efficient by, for example, using prior information to improve the set of sample points.
For example, when an objective includes minimizing Euclidean distance in the presence of obstacles, visibility graph techniques could be used to produce a prior set of sample points guaranteed to include the shortest path.
Additionally, if there is structure in the cost functions, which may be common in path-planning problems, then the sampling of new points could be based on information collected from the environment, allowing more search effort to be put in the more interesting regions.

Another area of future work is to combine MORRF* with Bellman's principle of optimality.
This could be done by setting a goal position as the root node in the algorithm and then generating a set of Pareto optimal paths.
The algorithm should then converge to the set of Pareto optimal from any vertex in the tree to the goal.
Additionally, if movement deviates from the original path, it should be very efficient to generate a new set of Pareto optimal paths from the new position to the goal position.

\section*{Acknowledgments}
Omitted for anonymous review.

\bibliographystyle{named}
\bibliography{reference}

\end{document}